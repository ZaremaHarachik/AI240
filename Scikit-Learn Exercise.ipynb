{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit Learn Exercise   AI240 - 10459\n",
    "## Instructor - Dr. Uma Gajendragadkar\n",
    "\n",
    "## Exercise 1 - \n",
    "First install Numpy Library (if it's not already installed) as it is required by Scikit Learn Library.\n",
    "\n",
    "!pip install numpy\n",
    "\n",
    "If already not installed, then  install Scikit Learn Library using below instruction on Jupyter Notebook\n",
    "\n",
    "!pip install scikit-learn\n",
    "\n",
    "Once the installation is complete, you can verify whether Scikit-learn is installed or not by typing the following command:\n",
    "\n",
    "pip show scikit-learn\n",
    "\n",
    "## Exercise 2 - \n",
    "First import pandas and numpy with below statements\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "Import the scikit Learn Library datasets with below statement\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "## Exercise 3 - \n",
    "Load default datsets - the iris dataset with below statetments.\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "The Iris dataset, a classic in machine learning, is a dataset of 150 iris flower measurements, including sepal and petal length and width, used for classification tasks, and is readily available within the scikit-learn library.\n",
    "\n",
    "A dataset is a dictionary-like object that holds all the data and some metadata about the data.The variables of data are called its features. They are also known as predictors or attributes.\n",
    "\n",
    "Feature matrix − It is the collection of features, in case there are more than one.\n",
    "\n",
    "Feature Names − list of names of the features.\n",
    "\n",
    "Response − It is the output variable that basically depends upon the feature variables. They are also known as target, label or output.\n",
    "\n",
    "Response Vector − It is used to represent response column. Generally, we have just one response column.\n",
    "\n",
    "Target Names − It represent the possible values taken by a response vector.\n",
    "\n",
    "## Exercise 4 - \n",
    "Lets's use IRIS dataset and execute below lines of code and check the output.\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data\n",
    "\n",
    "y = iris.target\n",
    "\n",
    "feature_names = iris.feature_names\n",
    "\n",
    "target_names = iris.target_names\n",
    "\n",
    "print(\"Feature names:\", feature_names)\n",
    "\n",
    "print(\"Target names:\", target_names)\n",
    "\n",
    "print(\"\\nFirst 10 rows of X:\\n\", X[:10])\n",
    "\n",
    "\n",
    "## Exercise 5 - \n",
    "Splitting the dataset\n",
    "Split the dataset into two pieces-a training set and a testing set. Use the training set to train the model and testing set to test the model. Execute below lines of code to split the data into 80:20 ratio . It means 80% data is training data and 20% as testing data.\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "print(X_test.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "\n",
    "print(y_test.shape)\n",
    "\n",
    "## Exercise 6 - \n",
    "Train the Model\n",
    "Use our dataset to train some prediction-model. Scikit-learn has wide range of Machine Learning (ML) algorithms.\n",
    "\n",
    "Here, we are going to use KNN (K nearest neighbors) classifier for sake of learning the scikit Library. We are going to learn classification in detail in coming weeks. Below lines of code are to be executed and are used to make you understand the implementation. \n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "classifier_knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "classifier_knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier_knn.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: /usr/share/pip-wheels\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (1.24.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: /usr/share/pip-wheels\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Target names: ['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "First 10 rows of X:\n",
      " [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "print(\"Feature names:\", feature_names)\n",
    "print(\"Target names:\", target_names)\n",
    "print(\"\\nFirst 10 rows of X:\\n\", X[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (120, 4)\n",
      "X_test shape: (30, 4)\n",
      "y_train shape: (120,)\n",
      "y_test shape: (30,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "# Then print\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "# Create a KNN classifier with 5 neighbors\n",
    "classifier_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model using the training data\n",
    "classifier_knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the responses for the test dataset\n",
    "y_pred = classifier_knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
